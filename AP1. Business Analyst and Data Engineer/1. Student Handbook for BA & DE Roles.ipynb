{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Manual & Handbook\n",
    "## Designing and Implementing Data Science Solutions on Azure\n",
    "\n",
    "**Preparation for Business Analyst and Data Engineer Roles**\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Course Overview\n",
    "\n",
    "This comprehensive manual prepares you for the **DP-100 certification** and equips you with practical skills for **Business Analyst** and **Data Engineer** roles in data science and machine learning.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Design and create suitable working environments for data science workloads\n",
    "- Explore data and train machine learning models on Azure Machine Learning\n",
    "- Run jobs and pipelines to prepare models for production\n",
    "- Deploy and monitor scalable machine learning solutions\n",
    "- Optimize language models for AI applications\n",
    "\n",
    "**Target Roles:**\n",
    "- Business Analyst (Data-focused)\n",
    "- Data Engineer\n",
    "- ML Engineer\n",
    "- Data Scientist\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 1: Design a Machine Learning Solution\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand the complete machine learning lifecycle\n",
    "- Design data ingestion solutions\n",
    "- Choose appropriate Azure services for ML workloads\n",
    "- Plan for model deployment and monitoring\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 The Machine Learning Process\n",
    "\n",
    "#### Six Key Steps:\n",
    "\n",
    "1. **Define the Problem** - Identify the business question and ML task type\n",
    "2. **Get the Data** - Source and collect relevant datasets\n",
    "3. **Prepare the Data** - Clean, transform, and engineer features\n",
    "4. **Train the Model** - Select and train algorithms\n",
    "5. **Integrate the Model** - Deploy for consumption\n",
    "6. **Monitor the Model** - Track performance and detect drift\n",
    "\n",
    "#### Common ML Problem Types:\n",
    "\n",
    "| Problem Type | Description | Example |\n",
    "|--------------|-------------|----------|\n",
    "| **Classification** | Predict categorical values | Customer churn (Yes/No) |\n",
    "| **Regression** | Predict numerical values | House price prediction |\n",
    "| **Time-series Forecasting** | Predict future values over time | Sales forecasting |\n",
    "| **Computer Vision** | Classify images or detect objects | Medical image diagnosis |\n",
    "| **NLP** | Process and understand text | Sentiment analysis |\n",
    "\n",
    "#### Business Analyst Perspective:\n",
    "- Translate business requirements into ML problems\n",
    "- Define success metrics (accuracy, precision, recall, F1-score)\n",
    "- Ensure alignment with business KPIs\n",
    "\n",
    "#### Data Engineer Perspective:\n",
    "- Design scalable data pipelines\n",
    "- Ensure data quality and consistency\n",
    "- Optimize data storage and retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Storage and Ingestion\n",
    "\n",
    "#### Azure Storage Options for ML:\n",
    "\n",
    "```python\n",
    "# Common Azure Storage Services for ML\n",
    "\"\"\"\n",
    "1. Azure Blob Storage\n",
    "   - Use Case: Unstructured data (images, videos, logs)\n",
    "   - Cost: Low\n",
    "   - Performance: Good for large files\n",
    "\n",
    "2. Azure Data Lake Storage (Gen 2)\n",
    "   - Use Case: Big data analytics, hierarchical data\n",
    "   - Cost: Low-Medium\n",
    "   - Performance: Optimized for analytics\n",
    "\n",
    "3. Azure SQL Database\n",
    "   - Use Case: Structured transactional data\n",
    "   - Cost: Medium-High\n",
    "   - Performance: High for structured queries\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### Data Types:\n",
    "\n",
    "- **Structured**: Tabular data (CSV, SQL tables)\n",
    "- **Semi-structured**: JSON, XML, Parquet\n",
    "- **Unstructured**: Images, text, audio, video\n",
    "\n",
    "#### Data Ingestion Architecture:\n",
    "\n",
    "```\n",
    "Data Source ‚Üí Azure Data Factory/Synapse ‚Üí Transform ‚Üí Azure Storage ‚Üí Azure ML\n",
    "    (CRM/IoT)         (ETL Pipeline)        (Clean)    (Blob/ADLS)    (Training)\n",
    "```\n",
    "\n",
    "#### Key Principle: **Separate Compute from Storage**\n",
    "- Scale compute up/down based on demand\n",
    "- Keep data persistent in storage\n",
    "- Shutdown compute when not needed to save costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Choosing Azure ML Services\n",
    "\n",
    "#### Service Comparison:\n",
    "\n",
    "| Service | Best For | Key Features | When to Use |\n",
    "|---------|----------|--------------|-------------|\n",
    "| **Azure AI Services** | Pre-built models | Quick deployment, minimal coding | Standard use cases (vision, speech, language) |\n",
    "| **Microsoft Fabric** | End-to-end data platform | Unified analytics | Data engineering + data science at scale |\n",
    "| **Azure Databricks** | Big data + ML | Spark, collaborative notebooks | Large-scale data processing |\n",
    "| **Azure Machine Learning** | Custom ML models | Full ML lifecycle management | Custom models, MLOps, tracking |\n",
    "\n",
    "#### Compute Options:\n",
    "\n",
    "**CPU vs GPU:**\n",
    "- CPU: Smaller tabular datasets, cost-effective\n",
    "- GPU: Unstructured data (images, text), deep learning\n",
    "\n",
    "**General Purpose vs Memory Optimized:**\n",
    "- General Purpose: Balanced CPU-to-memory, testing/development\n",
    "- Memory Optimized: High memory-to-CPU, in-memory analytics\n",
    "\n",
    "**Spark Compute:**\n",
    "- Driver node + worker nodes\n",
    "- Distributed processing\n",
    "- Available in Azure Synapse Analytics and Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Model Deployment Strategies\n",
    "\n",
    "#### Real-time vs Batch Deployment:\n",
    "\n",
    "| Aspect | Real-time | Batch |\n",
    "|--------|-----------|-------|\n",
    "| **Latency** | Milliseconds-seconds | Minutes-hours |\n",
    "| **Use Case** | Mobile apps, websites | Nightly reports, bulk processing |\n",
    "| **Compute** | Always-on | Scheduled/on-demand |\n",
    "| **Cost** | Higher (always running) | Lower (runs when needed) |\n",
    "| **Example** | Credit card fraud detection | Customer churn prediction |\n",
    "\n",
    "#### Deployment Endpoints:\n",
    "\n",
    "```python\n",
    "# Real-time Endpoint Example\n",
    "\"\"\"\n",
    "Client App ‚Üí REST API ‚Üí Model Endpoint ‚Üí Prediction Response\n",
    "          (HTTP POST)   (Always Available)  (Immediate)\n",
    "\"\"\"\n",
    "\n",
    "# Batch Endpoint Example\n",
    "\"\"\"\n",
    "Scheduled Job ‚Üí Batch Endpoint ‚Üí Process Data ‚Üí Save Results to Storage\n",
    "    (Daily)      (Spin up)      (Multiple rows)    (Database/File)\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 MLOps Architecture\n",
    "\n",
    "#### Six-Stage MLOps Workflow:\n",
    "\n",
    "1. **Setup**: Create Azure resources (Resource Group, Workspace, Compute)\n",
    "2. **Model Development** (Inner Loop): Explore data, train models\n",
    "3. **Continuous Integration**: Package and register models\n",
    "4. **Model Deployment** (Outer Loop): Deploy to endpoints\n",
    "5. **Continuous Deployment**: Test and promote to production\n",
    "6. **Monitoring**: Track performance and detect drift\n",
    "\n",
    "#### Monitoring Considerations:\n",
    "\n",
    "**Performance Metrics:**\n",
    "- Accuracy, Precision, Recall, F1-score\n",
    "- AUC-ROC for classification\n",
    "- RMSE, MAE for regression\n",
    "\n",
    "**Drift Detection:**\n",
    "- **Data Drift**: Input distribution changes\n",
    "- **Concept Drift**: Relationship between features and labels changes\n",
    "\n",
    "**Retraining Triggers:**\n",
    "- Metrics fall below threshold\n",
    "- Scheduled intervals\n",
    "- Detected drift\n",
    "- New data availability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì Module 1: Practice Questions\n",
    "\n",
    "#### Question 1\n",
    "Your company collects IoT sensor data every minute as JSON objects. What type of data is this?\n",
    "- A) Structured\n",
    "- B) Semi-structured ‚úì\n",
    "- C) Unstructured\n",
    "\n",
    "**Answer: B** - JSON is semi-structured data with a defined schema but flexible structure.\n",
    "\n",
    "#### Question 2\n",
    "Which Azure service should you use for quick iteration over multiple algorithms without extensive coding?\n",
    "- A) Azure AI Services\n",
    "- B) Automated Machine Learning ‚úì\n",
    "- C) Azure Databricks\n",
    "\n",
    "**Answer: B** - AutoML automatically tests multiple algorithms and preprocessing techniques.\n",
    "\n",
    "#### Question 3\n",
    "A mobile app needs instant predictions for credit card transactions. Which deployment should you use?\n",
    "- A) Batch deployment\n",
    "- B) Real-time deployment ‚úì\n",
    "- C) Scheduled deployment\n",
    "\n",
    "**Answer: B** - Real-time deployment provides immediate responses for transactional scenarios.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2: Azure Machine Learning Workspace\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Create and configure Azure ML workspaces\n",
    "- Understand workspace resources and assets\n",
    "- Use developer tools (Studio, Python SDK, Azure CLI)\n",
    "- Manage compute resources\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Azure ML Workspace Components\n",
    "\n",
    "#### Core Resources:\n",
    "\n",
    "| Resource | Description | Purpose |\n",
    "|----------|-------------|----------|\n",
    "| **Workspace** | Top-level resource | Central hub for ML operations |\n",
    "| **Compute Instances** | Development VMs | Interactive development with Jupyter |\n",
    "| **Compute Clusters** | Scalable compute | Training jobs and batch inference |\n",
    "| **Datastores** | Storage connections | Link to Azure Storage accounts |\n",
    "| **Linked Services** | External services | Azure Synapse, Azure Databricks |\n",
    "\n",
    "#### Workspace Assets:\n",
    "\n",
    "- **Models**: Trained ML models\n",
    "- **Environments**: Package dependencies\n",
    "- **Data**: Datasets and data assets\n",
    "- **Components**: Reusable pipeline steps\n",
    "- **Pipelines**: End-to-end workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Setting Up Azure ML Workspace\n",
    "\n",
    "#### Prerequisites:\n",
    "```python\n",
    "# Required Azure Resources\n",
    "\"\"\"\n",
    "1. Azure Subscription\n",
    "2. Resource Group\n",
    "3. Azure Machine Learning Workspace\n",
    "4. Associated Storage Account (auto-created)\n",
    "5. Application Insights (optional, for monitoring)\n",
    "6. Key Vault (optional, for secrets)\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation - Python SDK v2\n",
    "# Run this in your terminal or notebook\n",
    "!pip install azure-ai-ml azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Azure ML Workspace\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Replace with your details\n",
    "subscription_id = \"<your-subscription-id>\"\n",
    "resource_group = \"<your-resource-group>\"\n",
    "workspace_name = \"<your-workspace-name>\"\n",
    "\n",
    "# Authenticate and create client\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(),\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group_name=resource_group,\n",
    "    workspace_name=workspace_name\n",
    ")\n",
    "\n",
    "print(f\"Connected to workspace: {ml_client.workspace_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Role-Based Access Control (RBAC)\n",
    "\n",
    "#### Common Roles:\n",
    "\n",
    "| Role | Permissions | Use Case |\n",
    "|------|-------------|----------|\n",
    "| **Owner** | Full control | Workspace administrators |\n",
    "| **Contributor** | Create/modify resources | Team leads, senior engineers |\n",
    "| **AzureML Data Scientist** | Run experiments, train models | Data scientists, ML engineers |\n",
    "| **AzureML Compute Operator** | Manage compute | DevOps, cost managers |\n",
    "| **Reader** | View only | Stakeholders, auditors |\n",
    "\n",
    "#### Business Analyst Role:\n",
    "- Typically assigned **AzureML Data Scientist** or **Reader**\n",
    "- Can run experiments and view results\n",
    "- May need custom roles for specific business needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Developer Tools\n",
    "\n",
    "#### 1. Azure Machine Learning Studio\n",
    "- **Access**: https://ml.azure.com\n",
    "- **Use Case**: Visual interface, no-code/low-code development\n",
    "- **Features**:\n",
    "  - Designer (drag-and-drop ML)\n",
    "  - AutoML interface\n",
    "  - Experiment tracking\n",
    "  - Model management\n",
    "\n",
    "#### 2. Python SDK (v2)\n",
    "- **Use Case**: Code-first development, automation\n",
    "- **Best For**: Data scientists, ML engineers\n",
    "- **Features**:\n",
    "  - Full programmatic control\n",
    "  - Integration with notebooks\n",
    "  - Reproducible pipelines\n",
    "\n",
    "#### 3. Azure CLI\n",
    "- **Use Case**: DevOps, CI/CD pipelines, automation\n",
    "- **Best For**: Data engineers, DevOps engineers\n",
    "- **Features**:\n",
    "  - Command-line automation\n",
    "  - YAML-based configurations\n",
    "  - Script integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: List all compute targets in workspace\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "# List all compute resources\n",
    "compute_list = ml_client.compute.list()\n",
    "\n",
    "print(\"Available compute resources:\")\n",
    "for compute in compute_list:\n",
    "    print(f\"- {compute.name} (Type: {compute.type})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Working with Compute\n",
    "\n",
    "#### Compute Types:\n",
    "\n",
    "**1. Compute Instance (Dev Environment):**\n",
    "- Personal development VM\n",
    "- Jupyter, VS Code, RStudio\n",
    "- Always-on or scheduled\n",
    "- Good for: Interactive development\n",
    "\n",
    "**2. Compute Cluster (Training):**\n",
    "- Auto-scaling cluster\n",
    "- Min/max nodes configuration\n",
    "- Pay only when running\n",
    "- Good for: Distributed training, batch jobs\n",
    "\n",
    "**3. Inference Cluster (Deployment):**\n",
    "- Azure Kubernetes Service (AKS)\n",
    "- Managed endpoints\n",
    "- Production-grade\n",
    "- Good for: Real-time inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a compute cluster\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "compute_cluster = AmlCompute(\n",
    "    name=\"cpu-cluster\",\n",
    "    type=\"amlcompute\",\n",
    "    size=\"STANDARD_DS3_V2\",  # VM size\n",
    "    min_instances=0,          # Scale down to 0 when idle\n",
    "    max_instances=4,          # Max 4 nodes\n",
    "    idle_time_before_scale_down=120  # Wait 2 min before scaling down\n",
    ")\n",
    "\n",
    "# Create the compute cluster\n",
    "ml_client.compute.begin_create_or_update(compute_cluster).result()\n",
    "print(f\"Compute cluster '{compute_cluster.name}' created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Job Types in Azure ML\n",
    "\n",
    "#### Three Main Job Types:\n",
    "\n",
    "| Job Type | Purpose | When to Use |\n",
    "|----------|---------|-------------|\n",
    "| **Command** | Execute single script | Training a model, data preprocessing |\n",
    "| **Sweep** | Hyperparameter tuning | Optimize model parameters |\n",
    "| **Pipeline** | Multi-step workflow | End-to-end ML pipelines |\n",
    "\n",
    "#### Job Execution Flow:\n",
    "```\n",
    "Submit Job ‚Üí Queue ‚Üí Provision Compute ‚Üí Run Script ‚Üí Log Outputs ‚Üí Cleanup\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì Module 2: Practice Questions\n",
    "\n",
    "#### Question 1\n",
    "A data scientist needs to run training scripts as jobs. Which role provides the necessary permissions?\n",
    "- A) Reader\n",
    "- B) AzureML Data Scientist ‚úì\n",
    "- C) AzureML Compute Operator\n",
    "\n",
    "**Answer: B** - AzureML Data Scientist role allows running experiments and training jobs.\n",
    "\n",
    "#### Question 2\n",
    "What type of job should you use to train a single model with one script?\n",
    "- A) Command ‚úì\n",
    "- B) Pipeline\n",
    "- C) Sweep\n",
    "\n",
    "**Answer: A** - Command job executes a single script for model training.\n",
    "\n",
    "#### Question 3\n",
    "Which tool is best for automating weekly model retraining in a CI/CD pipeline?\n",
    "- A) Azure Machine Learning Studio\n",
    "- B) Python SDK\n",
    "- C) Azure CLI ‚úì\n",
    "\n",
    "**Answer: C** - Azure CLI integrates well with DevOps and CI/CD automation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 3: Automated Machine Learning (AutoML)\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand AutoML capabilities and benefits\n",
    "- Configure AutoML experiments\n",
    "- Select appropriate tasks and metrics\n",
    "- Interpret AutoML results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 What is Automated Machine Learning?\n",
    "\n",
    "#### Key Concept:\n",
    "AutoML automates the process of:\n",
    "- Feature engineering\n",
    "- Algorithm selection\n",
    "- Hyperparameter tuning\n",
    "- Model evaluation\n",
    "\n",
    "#### Benefits:\n",
    "- **Speed**: Train multiple models in parallel\n",
    "- **Efficiency**: No manual trial-and-error\n",
    "- **Quality**: Find optimal model configuration\n",
    "- **Accessibility**: Less ML expertise required\n",
    "\n",
    "#### When to Use AutoML:\n",
    "‚úÖ Quick prototyping and baseline models\n",
    "‚úÖ Limited ML expertise on the team\n",
    "‚úÖ Standard ML tasks (classification, regression)\n",
    "‚úÖ Need to compare multiple algorithms\n",
    "\n",
    "‚ùå Highly specialized custom models\n",
    "‚ùå Need complete control over every parameter\n",
    "‚ùå Novel ML architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 AutoML Task Types\n",
    "\n",
    "#### Supported Tasks:\n",
    "\n",
    "| Task | Use Case | Example | Output |\n",
    "|------|----------|---------|--------|\n",
    "| **Classification** | Predict categories | Email spam detection | Binary/Multi-class |\n",
    "| **Regression** | Predict numbers | House price prediction | Continuous value |\n",
    "| **Time-series Forecasting** | Predict future values | Sales forecasting | Time-ordered predictions |\n",
    "| **Computer Vision** | Image tasks | Object detection | Bounding boxes, labels |\n",
    "| **NLP** | Text analysis | Sentiment classification | Text labels |\n",
    "\n",
    "#### Business Analyst Use Cases:\n",
    "\n",
    "**Classification:**\n",
    "- Customer churn prediction\n",
    "- Lead scoring\n",
    "- Product recommendation\n",
    "\n",
    "**Regression:**\n",
    "- Revenue forecasting\n",
    "- Customer lifetime value\n",
    "- Pricing optimization\n",
    "\n",
    "**Time-series:**\n",
    "- Demand forecasting\n",
    "- Inventory planning\n",
    "- Budget prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Data Preparation for AutoML\n",
    "\n",
    "#### Data Requirements:\n",
    "\n",
    "**Classification & Regression:**\n",
    "- Tabular format (CSV, Parquet)\n",
    "- Clean column headers\n",
    "- Target column identified\n",
    "\n",
    "**Data Asset Types:**\n",
    "1. **File Dataset**: Points to files in storage\n",
    "2. **Tabular Dataset**: Structured as table\n",
    "3. **MLTable**: Includes schema definition\n",
    "\n",
    "#### Data Quality Checklist:\n",
    "- ‚úÖ Remove duplicates\n",
    "- ‚úÖ Handle missing values\n",
    "- ‚úÖ Encode categorical variables\n",
    "- ‚úÖ Normalize numerical features\n",
    "- ‚úÖ Split train/test appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an MLTable data asset\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "# Reference an existing data asset\n",
    "my_training_data = Input(\n",
    "    type=AssetTypes.MLTABLE,\n",
    "    path=\"azureml:diabetes-data:1\"  # name:version\n",
    ")\n",
    "\n",
    "print(f\"Data asset configured: {my_training_data.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Featurization in AutoML\n",
    "\n",
    "#### Automatic Featurization:\n",
    "\n",
    "**Scaling & Normalization:**\n",
    "- StandardScaler: Mean=0, StdDev=1\n",
    "- MinMaxScaler: Range [0,1]\n",
    "- RobustScaler: Handles outliers\n",
    "\n",
    "**Missing Value Imputation:**\n",
    "- Mean/Median for numerical\n",
    "- Mode for categorical\n",
    "- Forward fill for time-series\n",
    "\n",
    "**Categorical Encoding:**\n",
    "- One-hot encoding (< 10 categories)\n",
    "- Label encoding (many categories)\n",
    "- Target encoding (advanced)\n",
    "\n",
    "#### Configuration Options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure featurization\n",
    "from azure.ai.ml import automl\n",
    "\n",
    "# Example featurization config\n",
    "featurization_config = {\n",
    "    \"mode\": \"auto\",  # auto, custom, or off\n",
    "    \"blocked_transformers\": [\"LabelEncoder\"],  # Exclude specific transformers\n",
    "    \"column_purposes\": {\n",
    "        \"customer_id\": \"Ignore\",  # Don't use this column\n",
    "        \"purchase_date\": \"DateTime\"  # Treat as datetime\n",
    "    },\n",
    "    \"transformer_params\": {\n",
    "        \"Imputer\": {\"strategy\": \"median\"}  # Custom imputation\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Featurization configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Configuring an AutoML Classification Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete AutoML Classification Example\n",
    "from azure.ai.ml import automl\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "# Configure data\n",
    "my_training_data = Input(\n",
    "    type=AssetTypes.MLTABLE,\n",
    "    path=\"azureml:customer-churn-data:1\"\n",
    ")\n",
    "\n",
    "# Create classification job\n",
    "classification_job = automl.classification(\n",
    "    compute=\"cpu-cluster\",\n",
    "    experiment_name=\"customer-churn-classification\",\n",
    "    training_data=my_training_data,\n",
    "    target_column_name=\"Churn\",  # Column to predict\n",
    "    primary_metric=\"accuracy\",   # Optimization metric\n",
    "    n_cross_validations=5,       # Cross-validation folds\n",
    "    enable_model_explainability=True,\n",
    "    \n",
    "    # Limit training time\n",
    "    timeout_minutes=60,\n",
    "    max_concurrent_trials=4,\n",
    "    max_trials=20,\n",
    "    \n",
    "    # Featurization\n",
    "    featurization=\"auto\"\n",
    ")\n",
    "\n",
    "# Set training limits\n",
    "classification_job.set_limits(\n",
    "    timeout_minutes=60,\n",
    "    trial_timeout_minutes=20,\n",
    "    max_trials=20,\n",
    "    max_concurrent_trials=4\n",
    ")\n",
    "\n",
    "# Submit the job\n",
    "returned_job = ml_client.jobs.create_or_update(classification_job)\n",
    "print(f\"Job submitted: {returned_job.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 AutoML Metrics\n",
    "\n",
    "#### Classification Metrics:\n",
    "\n",
    "| Metric | Best For | Range | Goal |\n",
    "|--------|----------|-------|------|\n",
    "| **Accuracy** | Balanced classes | [0, 1] | Maximize |\n",
    "| **Precision** | Minimize false positives | [0, 1] | Maximize |\n",
    "| **Recall** | Minimize false negatives | [0, 1] | Maximize |\n",
    "| **F1 Score** | Balance precision/recall | [0, 1] | Maximize |\n",
    "| **AUC ROC** | Overall performance | [0, 1] | Maximize |\n",
    "\n",
    "#### Regression Metrics:\n",
    "\n",
    "| Metric | Description | Goal |\n",
    "|--------|-------------|------|\n",
    "| **R¬≤ Score** | Variance explained | Maximize (closer to 1) |\n",
    "| **RMSE** | Root mean squared error | Minimize |\n",
    "| **MAE** | Mean absolute error | Minimize |\n",
    "| **MAPE** | Mean absolute percentage error | Minimize |\n",
    "\n",
    "#### Choosing the Right Metric:\n",
    "\n",
    "**Business Impact Questions:**\n",
    "- What's more costly: false positives or false negatives?\n",
    "- Is class imbalance present?\n",
    "- What's the business KPI?\n",
    "\n",
    "**Example Scenarios:**\n",
    "- Medical diagnosis ‚Üí Recall (catch all sick patients)\n",
    "- Spam detection ‚Üí Precision (don't block real emails)\n",
    "- Credit scoring ‚Üí F1 Score (balance both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Interpreting AutoML Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and analyze AutoML results\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Get job details\n",
    "job_name = \"customer-churn-classification_123456\"\n",
    "job = ml_client.jobs.get(job_name)\n",
    "\n",
    "print(f\"Job Status: {job.status}\")\n",
    "print(f\"Best Model: {job.properties.get('best_child_run_id')}\")\n",
    "\n",
    "# Download outputs\n",
    "ml_client.jobs.download(job_name, download_path=\"./outputs\")\n",
    "print(\"Results downloaded to ./outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What to Look For:\n",
    "\n",
    "1. **Best Model**: Algorithm with highest metric score\n",
    "2. **Feature Importance**: Which features matter most?\n",
    "3. **Confusion Matrix**: Classification performance breakdown\n",
    "4. **Training Time**: Cost-performance tradeoff\n",
    "5. **Model Explainability**: SHAP values, feature contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì Module 3: Practice Questions\n",
    "\n",
    "#### Question 1\n",
    "Your marketing team wants to predict customer churn (Yes/No). Which AutoML task should you use?\n",
    "- A) Forecasting\n",
    "- B) Regression\n",
    "- C) Classification ‚úì\n",
    "\n",
    "**Answer: C** - Churn is a binary classification problem (churn vs not churn).\n",
    "\n",
    "#### Question 2\n",
    "A medical company wants to detect abnormalities in X-ray images. Which task should be used?\n",
    "- A) Forecasting\n",
    "- B) Computer Vision ‚úì\n",
    "- C) Natural Language Processing\n",
    "\n",
    "**Answer: B** - Image classification/object detection requires computer vision.\n",
    "\n",
    "#### Question 3\n",
    "For fraud detection where missing fraud is very costly, which metric should you optimize?\n",
    "- A) Precision\n",
    "- B) Recall ‚úì\n",
    "- C) Accuracy\n",
    "\n",
    "**Answer: B** - Recall minimizes false negatives (missed fraud cases).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 4: Training Custom Models\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Train models using Jupyter notebooks\n",
    "- Run training scripts as command jobs\n",
    "- Track experiments with MLflow\n",
    "- Perform hyperparameter tuning with sweep jobs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Training in Notebooks vs Scripts\n",
    "\n",
    "#### Comparison:\n",
    "\n",
    "| Aspect | Notebooks | Scripts |\n",
    "|--------|-----------|----------|\n",
    "| **Use Case** | Exploration, prototyping | Production, automation |\n",
    "| **Execution** | Interactive, cell-by-cell | End-to-end, automated |\n",
    "| **Tracking** | Manual logging | Automatic job tracking |\n",
    "| **Reproducibility** | Lower | Higher |\n",
    "| **Scalability** | Limited to instance | Distributed compute |\n",
    "| **Version Control** | Harder | Easier (Git) |\n",
    "\n",
    "#### Workflow:\n",
    "```\n",
    "Exploration (Notebook) ‚Üí Refine (Script) ‚Üí Production (Job)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 MLflow Tracking\n",
    "\n",
    "#### What is MLflow?\n",
    "- Open-source platform for ML lifecycle\n",
    "- Tracks experiments, parameters, metrics\n",
    "- Integrated with Azure ML\n",
    "- Language-agnostic (Python, R, Java)\n",
    "\n",
    "#### Key Concepts:\n",
    "\n",
    "**Experiment**: Collection of related runs\n",
    "**Run**: Single execution of training code\n",
    "**Parameters**: Input values (learning rate, batch size)\n",
    "**Metrics**: Output values (accuracy, loss)\n",
    "**Artifacts**: Files (models, plots, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MLflow\n",
    "!pip install mlflow azureml-mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Training with MLflow in a notebook\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Set experiment\n",
    "mlflow.set_experiment(\"diabetes-classification\")\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Load data\n",
    "    df = pd.read_csv('diabetes.csv')\n",
    "    \n",
    "    # Prepare data\n",
    "    X = df.drop('Diabetic', axis=1)\n",
    "    y = df['Diabetic']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Log parameters\n",
    "    n_estimators = 100\n",
    "    max_depth = 10\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    mlflow.log_param(\"test_size\", 0.2)\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Log metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model, \"random_forest_model\")\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Running Scripts as Command Jobs\n",
    "\n",
    "#### Why Use Command Jobs?\n",
    "- Reproducible execution\n",
    "- Automatic tracking\n",
    "- Distributed compute\n",
    "- Environment management\n",
    "- Easy scheduling\n",
    "\n",
    "#### Training Script Structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_script.py (save this as a separate file)\n",
    "\"\"\"\n",
    "import argparse\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Parse arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-path', type=str, help='Path to training data')\n",
    "parser.add_argument('--n-estimators', type=int, default=100)\n",
    "parser.add_argument('--max-depth', type=int, default=10)\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Enable autologging\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(args.data_path)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=args.n_estimators,\n",
    "    max_depth=args.max_depth\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\"\"\"\n",
    "print(\"Training script template created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit a command job\n",
    "from azure.ai.ml import command, Input\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# Configure input data\n",
    "data_input = Input(\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    path=\"azureml:diabetes-data:1\"\n",
    ")\n",
    "\n",
    "# Create command job\n",
    "job = command(\n",
    "    code=\"./src\",  # Folder with training script\n",
    "    command=\"python training_script.py --data-path ${{inputs.data}} --n-estimators ${{inputs.n_estimators}}\",\n",
    "    inputs={\n",
    "        \"data\": data_input,\n",
    "        \"n_estimators\": 200\n",
    "    },\n",
    "    environment=\"azureml:sklearn-env:1\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    experiment_name=\"diabetes-training\",\n",
    "    display_name=\"random-forest-training\"\n",
    ")\n",
    "\n",
    "# Submit job\n",
    "returned_job = ml_client.jobs.create_or_update(job)\n",
    "print(f\"Job submitted: {returned_job.name}\")\n",
    "print(f\"Studio URL: {returned_job.studio_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Hyperparameter Tuning with Sweep Jobs\n",
    "\n",
    "#### What is Hyperparameter Tuning?\n",
    "Systematically searching for the best combination of hyperparameters to optimize model performance.\n",
    "\n",
    "#### Search Strategies:\n",
    "\n",
    "| Strategy | How It Works | Best For |\n",
    "|----------|--------------|----------|\n",
    "| **Grid Search** | Try all combinations | Small parameter spaces |\n",
    "| **Random Search** | Random sampling | Large parameter spaces |\n",
    "| **Bayesian** | Smart sampling based on previous results | Expensive evaluations |\n",
    "\n",
    "#### Common Hyperparameters:\n",
    "\n",
    "**Tree-based Models:**\n",
    "- n_estimators (number of trees)\n",
    "- max_depth (tree depth)\n",
    "- min_samples_split\n",
    "- learning_rate (for boosting)\n",
    "\n",
    "**Neural Networks:**\n",
    "- learning_rate\n",
    "- batch_size\n",
    "- number of layers\n",
    "- dropout_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Sweep Job for Hyperparameter Tuning\n",
    "from azure.ai.ml.sweep import Choice, Uniform, Normal\n",
    "\n",
    "# Define command job (template)\n",
    "job_to_sweep = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python training_script.py --data-path ${{inputs.data}} --n-estimators ${{search_space.n_estimators}} --max-depth ${{search_space.max_depth}} --learning-rate ${{search_space.learning_rate}}\",\n",
    "    inputs={\n",
    "        \"data\": data_input\n",
    "    },\n",
    "    environment=\"azureml:sklearn-env:1\",\n",
    "    compute=\"cpu-cluster\"\n",
    ")\n",
    "\n",
    "# Define search space\n",
    "sweep_job = job_to_sweep.sweep(\n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"accuracy\",\n",
    "    goal=\"Maximize\",\n",
    "    search_space={\n",
    "        \"n_estimators\": Choice([50, 100, 200, 300]),\n",
    "        \"max_depth\": Choice([5, 10, 15, 20]),\n",
    "        \"learning_rate\": Uniform(0.01, 0.1)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Set limits\n",
    "sweep_job.set_limits(\n",
    "    max_total_trials=20,\n",
    "    max_concurrent_trials=4,\n",
    "    timeout_minutes=60\n",
    ")\n",
    "\n",
    "# Early termination policy (stop poor performers)\n",
    "from azure.ai.ml.sweep import BanditPolicy\n",
    "sweep_job.early_termination = BanditPolicy(\n",
    "    slack_factor=0.1,\n",
    "    evaluation_interval=1,\n",
    "    delay_evaluation=5\n",
    ")\n",
    "\n",
    "# Submit sweep job\n",
    "returned_sweep = ml_client.jobs.create_or_update(sweep_job)\n",
    "print(f\"Sweep job submitted: {returned_sweep.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Early Termination Policies\n",
    "\n",
    "Save compute costs by stopping underperforming trials early.\n",
    "\n",
    "#### Policy Types:\n",
    "\n",
    "**1. Bandit Policy:**\n",
    "- Terminates runs that don't perform within a slack factor of the best run\n",
    "- Good for: Most scenarios\n",
    "\n",
    "**2. Median Stopping:**\n",
    "- Terminates runs whose best metric is worse than median\n",
    "- Good for: Conservative stopping\n",
    "\n",
    "**3. Truncation Selection:**\n",
    "- Cancels a percentage of lowest-performing runs\n",
    "- Good for: Aggressive stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early termination policy examples\n",
    "from azure.ai.ml.sweep import BanditPolicy, MedianStoppingPolicy, TruncationSelectionPolicy\n",
    "\n",
    "# Bandit Policy\n",
    "bandit_policy = BanditPolicy(\n",
    "    slack_factor=0.15,  # Allow 15% slack from best performance\n",
    "    evaluation_interval=2,  # Check every 2 iterations\n",
    "    delay_evaluation=5  # Don't evaluate until 5 iterations complete\n",
    ")\n",
    "\n",
    "# Median Stopping Policy\n",
    "median_policy = MedianStoppingPolicy(\n",
    "    evaluation_interval=1,\n",
    "    delay_evaluation=5\n",
    ")\n",
    "\n",
    "# Truncation Selection Policy\n",
    "truncation_policy = TruncationSelectionPolicy(\n",
    "    truncation_percentage=20,  # Cancel bottom 20% of runs\n",
    "    evaluation_interval=1,\n",
    "    delay_evaluation=5\n",
    ")\n",
    "\n",
    "print(\"Early termination policies configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì Module 4: Practice Questions\n",
    "\n",
    "#### Question 1\n",
    "What's the primary advantage of using command jobs over notebook training?\n",
    "- A) Easier to write\n",
    "- B) Better for exploration\n",
    "- C) More reproducible and scalable ‚úì\n",
    "\n",
    "**Answer: C** - Command jobs provide reproducibility, automatic tracking, and distributed compute.\n",
    "\n",
    "#### Question 2\n",
    "Which hyperparameter tuning strategy is best for large parameter spaces?\n",
    "- A) Grid Search\n",
    "- B) Random Search ‚úì\n",
    "- C) Manual tuning\n",
    "\n",
    "**Answer: B** - Random search efficiently samples large spaces without trying all combinations.\n",
    "\n",
    "#### Question 3\n",
    "What does MLflow autolog() do?\n",
    "- A) Automatically saves the model\n",
    "- B) Automatically logs parameters, metrics, and models ‚úì\n",
    "- C) Automatically deploys the model\n",
    "\n",
    "**Answer: B** - autolog() tracks parameters, metrics, and artifacts automatically.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 5: Pipelines and Model Management\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Design and implement ML pipelines\n",
    "- Register and version models\n",
    "- Use Responsible AI dashboard\n",
    "- Prepare models for deployment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 ML Pipelines Overview\n",
    "\n",
    "#### What is an ML Pipeline?\n",
    "A sequence of interconnected steps that automate the ML workflow from data preparation to model training.\n",
    "\n",
    "#### Benefits:\n",
    "- **Reproducibility**: Same inputs = same outputs\n",
    "- **Automation**: Schedule and trigger automatically\n",
    "- **Modularity**: Reuse components across pipelines\n",
    "- **Scalability**: Parallel execution of steps\n",
    "- **Collaboration**: Share pipelines across teams\n",
    "\n",
    "#### Common Pipeline Steps:\n",
    "1. Data ingestion\n",
    "2. Data validation\n",
    "3. Data transformation\n",
    "4. Feature engineering\n",
    "5. Model training\n",
    "6. Model evaluation\n",
    "7. Model registration\n",
    "\n",
    "#### Business Value:\n",
    "- Faster time to production\n",
    "- Consistent model quality\n",
    "- Easier compliance and auditing\n",
    "- Reduced manual errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Simple 3-Step Pipeline\n",
    "from azure.ai.ml import load_component\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "\n",
    "# Load pre-built components (can also create custom)\n",
    "prep_data = load_component(source=\"./components/prep_data.yml\")\n",
    "train_model = load_component(source=\"./components/train_model.yml\")\n",
    "evaluate_model = load_component(source=\"./components/evaluate_model.yml\")\n",
    "\n",
    "# Define pipeline\n",
    "@pipeline(\n",
    "    name=\"diabetes-training-pipeline\",\n",
    "    description=\"Complete training pipeline for diabetes prediction\",\n",
    "    compute=\"cpu-cluster\"\n",
    ")\n",
    "def diabetes_pipeline(pipeline_input_data):\n",
    "    # Step 1: Prepare data\n",
    "    prep_step = prep_data(input_data=pipeline_input_data)\n",
    "    \n",
    "    # Step 2: Train model\n",
    "    train_step = train_model(\n",
    "        training_data=prep_step.outputs.output_data,\n",
    "        n_estimators=100,\n",
    "        max_depth=10\n",
    "    )\n",
    "    \n",
    "    # Step 3: Evaluate model\n",
    "    eval_step = evaluate_model(\n",
    "        model=train_step.outputs.model,\n",
    "        test_data=prep_step.outputs.test_data\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"trained_model\": train_step.outputs.model,\n",
    "        \"evaluation_results\": eval_step.outputs.metrics\n",
    "    }\n",
    "\n",
    "# Create pipeline instance\n",
    "pipeline_job = diabetes_pipeline(\n",
    "    pipeline_input_data=Input(type=AssetTypes.URI_FOLDER, path=\"azureml:diabetes-data:1\")\n",
    ")\n",
    "\n",
    "# Submit pipeline\n",
    "returned_pipeline = ml_client.jobs.create_or_update(pipeline_job)\n",
    "print(f\"Pipeline submitted: {returned_pipeline.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Creating Reusable Components\n",
    "\n",
    "#### Component Structure:\n",
    "A component consists of:\n",
    "- **Interface**: Inputs, outputs, parameters\n",
    "- **Implementation**: Script to execute\n",
    "- **Environment**: Dependencies\n",
    "\n",
    "#### Component YAML Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep_data.yml\n",
    "\"\"\"\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
    "name: prep_data\n",
    "display_name: Prepare Data\n",
    "version: 1\n",
    "type: command\n",
    "\n",
    "inputs:\n",
    "  input_data:\n",
    "    type: uri_folder\n",
    "    description: Raw input data\n",
    "  test_split:\n",
    "    type: number\n",
    "    default: 0.2\n",
    "    description: Test set percentage\n",
    "\n",
    "outputs:\n",
    "  output_data:\n",
    "    type: uri_folder\n",
    "    description: Prepared training data\n",
    "  test_data:\n",
    "    type: uri_folder\n",
    "    description: Test data\n",
    "\n",
    "code: ./src\n",
    "environment: azureml:sklearn-env:1\n",
    "command: >\n",
    "  python prep_data.py \n",
    "  --input-data ${{inputs.input_data}}\n",
    "  --test-split ${{inputs.test_split}}\n",
    "  --output-data ${{outputs.output_data}}\n",
    "  --test-data ${{outputs.test_data}}\n",
    "\"\"\"\n",
    "print(\"Component YAML template\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Model Registration and Versioning\n",
    "\n",
    "#### Why Register Models?\n",
    "- **Version Control**: Track model evolution\n",
    "- **Lineage**: Know how model was created\n",
    "- **Governance**: Control model access\n",
    "- **Deployment**: Deploy from registry\n",
    "- **Comparison**: Compare model versions\n",
    "\n",
    "#### Model Metadata:\n",
    "- Name and version\n",
    "- Description and tags\n",
    "- Training job ID\n",
    "- Metrics and parameters\n",
    "- Framework (sklearn, tensorflow, pytorch)\n",
    "- Model file location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register a model\n",
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# Register from job output\n",
    "model = Model(\n",
    "    path=\"azureml://jobs/{job_id}/outputs/artifacts/paths/model/\",\n",
    "    name=\"diabetes-classifier\",\n",
    "    description=\"Random Forest classifier for diabetes prediction\",\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    "    tags={\n",
    "        \"framework\": \"sklearn\",\n",
    "        \"algorithm\": \"RandomForest\",\n",
    "        \"accuracy\": \"0.89\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Register the model\n",
    "registered_model = ml_client.models.create_or_update(model)\n",
    "print(f\"Model registered: {registered_model.name} version {registered_model.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List and retrieve models\n",
    "# List all versions of a model\n",
    "models = ml_client.models.list(name=\"diabetes-classifier\")\n",
    "\n",
    "print(\"Available model versions:\")\n",
    "for model in models:\n",
    "    print(f\"- Version {model.version}: {model.description}\")\n",
    "\n",
    "# Get specific version\n",
    "model_v1 = ml_client.models.get(name=\"diabetes-classifier\", version=\"1\")\n",
    "print(f\"\\nRetrieved: {model_v1.name} v{model_v1.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Responsible AI Dashboard\n",
    "\n",
    "#### Purpose:\n",
    "Assess and improve ML model fairness, interpretability, and reliability.\n",
    "\n",
    "#### Dashboard Components:\n",
    "\n",
    "| Component | What It Shows | Why It Matters |\n",
    "|-----------|---------------|----------------|\n",
    "| **Error Analysis** | Where model fails | Target improvements |\n",
    "| **Model Explanations** | Feature importance | Build trust, debug |\n",
    "| **Fairness Assessment** | Performance across groups | Ensure equity |\n",
    "| **Causal Analysis** | Treatment effects | What-if scenarios |\n",
    "| **Counterfactuals** | Minimum changes for different prediction | Actionable insights |\n",
    "\n",
    "#### Business Analyst Use Cases:\n",
    "- Identify model biases\n",
    "- Explain predictions to stakeholders\n",
    "- Ensure regulatory compliance\n",
    "- Build customer trust\n",
    "\n",
    "#### Creating a Responsible AI Dashboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create Responsible AI dashboard\n",
    "from azure.ai.ml import command\n",
    "from azure.ai.ml.entities import RAIInsights\n",
    "\n",
    "# Create RAI insights\n",
    "rai_insights = RAIInsights(\n",
    "    target_column_name=\"Diabetic\",\n",
    "    task_type=\"classification\",\n",
    "    model_info={\n",
    "        \"model_name\": \"diabetes-classifier\",\n",
    "        \"model_version\": \"1\"\n",
    "    },\n",
    "    train_dataset=train_data,\n",
    "    test_dataset=test_data\n",
    ")\n",
    "\n",
    "# Add components\n",
    "rai_insights.add_explainer(\n",
    "    method=\"mimic\",  # or 'shap', 'lime'\n",
    "    model_task=\"classification\"\n",
    ")\n",
    "\n",
    "rai_insights.add_error_analysis(\n",
    "    max_depth=3,\n",
    "    num_leaves=15\n",
    ")\n",
    "\n",
    "rai_insights.add_fairness(\n",
    "    sensitive_features=[\"Age\", \"Gender\"],\n",
    "    fairness_metrics=[\"demographic_parity\", \"equalized_odds\"]\n",
    ")\n",
    "\n",
    "print(\"Responsible AI dashboard configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì Module 5: Practice Questions\n",
    "\n",
    "#### Question 1\n",
    "What's the main benefit of using ML pipelines?\n",
    "- A) Faster training\n",
    "- B) Better accuracy\n",
    "- C) Reproducibility and automation ‚úì\n",
    "\n",
    "**Answer: C** - Pipelines ensure consistent, repeatable workflows that can be automated.\n",
    "\n",
    "#### Question 2\n",
    "Why should you register models in Azure ML?\n",
    "- A) It's required for deployment\n",
    "- B) For version control and lineage tracking ‚úì\n",
    "- C) To improve model accuracy\n",
    "\n",
    "**Answer: B** - Registration enables versioning, tracking, and governance.\n",
    "\n",
    "#### Question 3\n",
    "Which Responsible AI component shows where your model performs poorly?\n",
    "- A) Model Explanations\n",
    "- B) Error Analysis ‚úì\n",
    "- C) Fairness Assessment\n",
    "\n",
    "**Answer: B** - Error Analysis identifies cohorts where the model fails.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 6: Model Deployment\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Deploy models to managed online endpoints\n",
    "- Deploy models to batch endpoints\n",
    "- Monitor deployed models\n",
    "- Implement blue-green deployments\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Deployment Options\n",
    "\n",
    "#### Endpoint Types:\n",
    "\n",
    "| Type | Use Case | Latency | Cost | Availability |\n",
    "|------|----------|---------|------|--------------|\n",
    "| **Managed Online** | Real-time predictions | Low (ms) | Higher | Always on |\n",
    "| **Batch** | Bulk predictions | High (min-hrs) | Lower | On-demand |\n",
    "| **Real-time (AKS)** | High-scale production | Low (ms) | Highest | Always on |\n",
    "\n",
    "#### Decision Flowchart:\n",
    "```\n",
    "Need real-time predictions? \n",
    "‚îú‚îÄ Yes ‚Üí High traffic expected?\n",
    "‚îÇ         ‚îú‚îÄ Yes ‚Üí Real-time (AKS)\n",
    "‚îÇ         ‚îî‚îÄ No  ‚Üí Managed Online Endpoint\n",
    "‚îî‚îÄ No  ‚Üí Batch Endpoint\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Managed Online Endpoints\n",
    "\n",
    "#### Key Features:\n",
    "- Automatic scaling\n",
    "- Blue-green deployments\n",
    "- Built-in monitoring\n",
    "- Authentication (key/token)\n",
    "- HTTPS endpoint\n",
    "\n",
    "#### Deployment Process:\n",
    "1. Register model\n",
    "2. Create endpoint\n",
    "3. Create deployment\n",
    "4. Allocate traffic\n",
    "5. Test endpoint\n",
    "6. Monitor performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy to Managed Online Endpoint\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration\n",
    ")\n",
    "\n",
    "# Step 1: Create endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=\"diabetes-endpoint\",\n",
    "    description=\"Endpoint for diabetes predictions\",\n",
    "    auth_mode=\"key\"  # or 'aml_token'\n",
    ")\n",
    "\n",
    "# Create the endpoint\n",
    "endpoint = ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "print(f\"Endpoint created: {endpoint.name}\")\n",
    "\n",
    "# Step 2: Create deployment\n",
    "deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=\"diabetes-endpoint\",\n",
    "    model=\"azureml:diabetes-classifier:1\",\n",
    "    instance_type=\"Standard_DS3_v2\",\n",
    "    instance_count=1,\n",
    "    environment=\"azureml:sklearn-env:1\",\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"./deployment\",\n",
    "        scoring_script=\"score.py\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Deploy\n",
    "deployment = ml_client.online_deployments.begin_create_or_update(deployment).result()\n",
    "print(f\"Deployment created: {deployment.name}\")\n",
    "\n",
    "# Step 3: Allocate traffic\n",
    "endpoint.traffic = {\"blue\": 100}  # 100% to blue deployment\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "print(\"Traffic allocated to blue deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring Script (score.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score.py - Scoring script for deployment\n",
    "\"\"\"\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # Load model\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "    print('Model loaded')\n",
    "\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        # Parse input\n",
    "        data = json.loads(raw_data)['data']\n",
    "        data = np.array(data)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = model.predict(data)\n",
    "        probabilities = model.predict_proba(data)\n",
    "        \n",
    "        # Return results\n",
    "        return {\n",
    "            'predictions': predictions.tolist(),\n",
    "            'probabilities': probabilities.tolist()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\"\"\"\n",
    "print(\"Scoring script template\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the endpoint\n",
    "import json\n",
    "\n",
    "# Prepare test data\n",
    "test_data = {\n",
    "    \"data\": [\n",
    "        [1, 85, 66, 29, 0, 26.6, 0.351, 31],  # Sample 1\n",
    "        [8, 183, 64, 0, 0, 23.3, 0.672, 32]   # Sample 2\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to JSON\n",
    "request_data = json.dumps(test_data)\n",
    "\n",
    "# Invoke endpoint\n",
    "response = ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=\"diabetes-endpoint\",\n",
    "    request_file=request_data\n",
    ")\n",
    "\n",
    "print(\"Predictions:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Blue-Green Deployment Strategy\n",
    "\n",
    "#### What is Blue-Green Deployment?\n",
    "Deploy a new version (green) alongside the current version (blue), then gradually shift traffic.\n",
    "\n",
    "#### Benefits:\n",
    "- **Zero downtime**: Always have a working version\n",
    "- **Safe rollout**: Test before full deployment\n",
    "- **Easy rollback**: Switch back if issues arise\n",
    "- **A/B testing**: Compare versions with real traffic\n",
    "\n",
    "#### Deployment Steps:\n",
    "1. Deploy green version (0% traffic)\n",
    "2. Test green version\n",
    "3. Gradually shift traffic (10% ‚Üí 50% ‚Üí 100%)\n",
    "4. Monitor metrics\n",
    "5. Delete blue version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blue-Green Deployment Example\n",
    "\n",
    "# Create green deployment\n",
    "green_deployment = ManagedOnlineDeployment(\n",
    "    name=\"green\",\n",
    "    endpoint_name=\"diabetes-endpoint\",\n",
    "    model=\"azureml:diabetes-classifier:2\",  # New version\n",
    "    instance_type=\"Standard_DS3_v2\",\n",
    "    instance_count=1,\n",
    "    environment=\"azureml:sklearn-env:1\"\n",
    ")\n",
    "\n",
    "# Deploy green (0% traffic initially)\n",
    "ml_client.online_deployments.begin_create_or_update(green_deployment).result()\n",
    "print(\"Green deployment created with 0% traffic\")\n",
    "\n",
    "# Test green deployment\n",
    "# ... test code ...\n",
    "\n",
    "# Gradually shift traffic\n",
    "endpoint.traffic = {\"blue\": 90, \"green\": 10}  # 10% to green\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "print(\"Traffic: 90% blue, 10% green\")\n",
    "\n",
    "# Monitor and continue shifting\n",
    "endpoint.traffic = {\"blue\": 50, \"green\": 50}  # 50/50 split\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "print(\"Traffic: 50% blue, 50% green\")\n",
    "\n",
    "# Complete migration\n",
    "endpoint.traffic = {\"blue\": 0, \"green\": 100}  # 100% to green\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "print(\"Traffic: 100% green\")\n",
    "\n",
    "# Delete blue deployment\n",
    "ml_client.online_deployments.begin_delete(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=\"diabetes-endpoint\"\n",
    ").result()\n",
    "print(\"Blue deployment deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Batch Endpoints\n",
    "\n",
    "#### When to Use Batch Endpoints:\n",
    "- Scheduled predictions (nightly, weekly)\n",
    "- Large datasets (thousands-millions of rows)\n",
    "- No real-time requirement\n",
    "- Cost optimization (pay only when running)\n",
    "\n",
    "#### Use Cases:\n",
    "- Customer churn scoring (monthly)\n",
    "- Product recommendations (daily)\n",
    "- Fraud detection (batch analysis)\n",
    "- Market segmentation (quarterly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy to Batch Endpoint\n",
    "from azure.ai.ml.entities import (\n",
    "    BatchEndpoint,\n",
    "    BatchDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration\n",
    ")\n",
    "\n",
    "# Create batch endpoint\n",
    "batch_endpoint = BatchEndpoint(\n",
    "    name=\"diabetes-batch\",\n",
    "    description=\"Batch endpoint for diabetes predictions\"\n",
    ")\n",
    "\n",
    "ml_client.batch_endpoints.begin_create_or_update(batch_endpoint).result()\n",
    "print(f\"Batch endpoint created: {batch_endpoint.name}\")\n",
    "\n",
    "# Create batch deployment\n",
    "batch_deployment = BatchDeployment(\n",
    "    name=\"diabetes-batch-v1\",\n",
    "    endpoint_name=\"diabetes-batch\",\n",
    "    model=\"azureml:diabetes-classifier:1\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    instance_count=2,\n",
    "    max_concurrency_per_instance=2,\n",
    "    mini_batch_size=10,\n",
    "    output_action=\"append_row\",\n",
    "    output_file_name=\"predictions.csv\",\n",
    "    retry_settings={\"max_retries\": 3, \"timeout\": 300},\n",
    "    logging_level=\"info\"\n",
    ")\n",
    "\n",
    "ml_client.batch_deployments.begin_create_or_update(batch_deployment).result()\n",
    "print(f\"Batch deployment created: {batch_deployment.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke batch endpoint\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# Prepare input data\n",
    "input_data = Input(\n",
    "    type=AssetTypes.URI_FOLDER,\n",
    "    path=\"azureml:batch-scoring-data:1\"\n",
    ")\n",
    "\n",
    "# Invoke batch job\n",
    "batch_job = ml_client.batch_endpoints.invoke(\n",
    "    endpoint_name=\"diabetes-batch\",\n",
    "    inputs={\"data\": input_data}\n",
    ")\n",
    "\n",
    "print(f\"Batch job submitted: {batch_job.name}\")\n",
    "\n",
    "# Monitor job\n",
    "ml_client.jobs.stream(batch_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Monitoring Deployed Models\n",
    "\n",
    "#### Key Metrics to Monitor:\n",
    "\n",
    "**Performance Metrics:**\n",
    "- Latency (response time)\n",
    "- Throughput (requests/second)\n",
    "- Error rate\n",
    "- CPU/Memory utilization\n",
    "\n",
    "**Model Metrics:**\n",
    "- Prediction accuracy\n",
    "- Data drift\n",
    "- Model drift\n",
    "- Feature distribution\n",
    "\n",
    "**Business Metrics:**\n",
    "- Usage patterns\n",
    "- User satisfaction\n",
    "- ROI impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable Application Insights monitoring\n",
    "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
    "\n",
    "# Get endpoint\n",
    "endpoint = ml_client.online_endpoints.get(\"diabetes-endpoint\")\n",
    "\n",
    "# Check monitoring configuration\n",
    "print(f\"Application Insights: {endpoint.application_insights}\")\n",
    "print(f\"Scoring URI: {endpoint.scoring_uri}\")\n",
    "print(f\"Primary Key: {endpoint.keys.primary_key[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì Module 6: Practice Questions\n",
    "\n",
    "#### Question 1\n",
    "A mobile app needs instant predictions for user interactions. Which deployment should you use?\n",
    "- A) Batch endpoint\n",
    "- B) Managed online endpoint ‚úì\n",
    "- C) Pipeline endpoint\n",
    "\n",
    "**Answer: B** - Online endpoints provide low-latency, real-time predictions.\n",
    "\n",
    "#### Question 2\n",
    "What's the main benefit of blue-green deployment?\n",
    "- A) Faster deployment\n",
    "- B) Lower cost\n",
    "- C) Zero-downtime updates ‚úì\n",
    "\n",
    "**Answer: C** - Blue-green deployment allows safe, zero-downtime version updates.\n",
    "\n",
    "#### Question 3\n",
    "When should you use batch endpoints?\n",
    "- A) Real-time user requests\n",
    "- B) Scheduled bulk predictions ‚úì\n",
    "- C) Low-latency scenarios\n",
    "\n",
    "**Answer: B** - Batch endpoints are ideal for scheduled, bulk prediction workloads.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 7: Language Models and AI Optimization\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Explore models from Azure AI catalog\n",
    "- Optimize performance with prompt engineering\n",
    "- Implement Retrieval Augmented Generation (RAG)\n",
    "- Fine-tune language models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Azure AI Model Catalog\n",
    "\n",
    "#### What's Available:\n",
    "\n",
    "| Category | Examples | Use Cases |\n",
    "|----------|----------|----------|\n",
    "| **Language Models** | GPT-4, GPT-3.5, Llama 2 | Text generation, Q&A, summarization |\n",
    "| **Vision Models** | Florence, CLIP | Image classification, OCR |\n",
    "| **Speech Models** | Whisper | Speech-to-text, transcription |\n",
    "| **Open Source** | BERT, T5, Falcon | Custom NLP tasks |\n",
    "\n",
    "#### Model Selection Criteria:\n",
    "- **Task requirements**: What do you need to accomplish?\n",
    "- **Performance**: Speed vs accuracy tradeoff\n",
    "- **Cost**: Inference cost per token\n",
    "- **Customization**: Can you fine-tune?\n",
    "- **Compliance**: Data residency, privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browse and deploy from model catalog\n",
    "from azure.ai.ml.entities import Model\n",
    "\n",
    "# List available models\n",
    "models = ml_client.models.list()\n",
    "\n",
    "print(\"Available models in catalog:\")\n",
    "for model in models:\n",
    "    print(f\"- {model.name} ({model.version})\")\n",
    "    print(f\"  Description: {model.description}\")\n",
    "    print(f\"  Tags: {model.tags}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Prompt Engineering\n",
    "\n",
    "#### What is Prompt Engineering?\n",
    "The art and science of crafting effective inputs (prompts) to get desired outputs from language models.\n",
    "\n",
    "#### Key Principles:\n",
    "\n",
    "1. **Be Specific**: Clear, detailed instructions\n",
    "2. **Provide Context**: Background information\n",
    "3. **Use Examples**: Show desired format (few-shot learning)\n",
    "4. **Set Tone/Style**: Specify how to respond\n",
    "5. **Iterate**: Refine based on results\n",
    "\n",
    "#### Prompt Patterns:\n",
    "\n",
    "**Zero-shot:**\n",
    "```\n",
    "Classify the sentiment: \"I love this product!\"\n",
    "```\n",
    "\n",
    "**Few-shot:**\n",
    "```\n",
    "Classify sentiment:\n",
    "\"Great service!\" ‚Üí Positive\n",
    "\"Terrible experience\" ‚Üí Negative\n",
    "\"It's okay\" ‚Üí Neutral\n",
    "\"Amazing quality!\" ‚Üí ?\n",
    "```\n",
    "\n",
    "**Chain-of-thought:**\n",
    "```\n",
    "Let's solve this step by step:\n",
    "1. First, identify...\n",
    "2. Then, calculate...\n",
    "3. Finally, conclude...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Engineering for Business Use Cases:\n",
    "\n",
    "**Customer Support:**\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "You are a helpful customer support agent for an e-commerce company.\n",
    "Respond professionally and empathetically.\n",
    "\n",
    "Customer: My order hasn't arrived yet.\n",
    "Agent:\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Data Analysis:**\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Analyze this sales data and provide 3 key insights:\n",
    "\n",
    "Q1 Sales: $250K\n",
    "Q2 Sales: $180K\n",
    "Q3 Sales: $320K\n",
    "Q4 Sales: $290K\n",
    "\n",
    "Insights:\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Report Generation:**\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Write a executive summary of this data in bullet points:\n",
    "- Focus on trends\n",
    "- Highlight risks\n",
    "- Suggest actions\n",
    "\n",
    "Data: [your data here]\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using Prompty for prompt engineering\n",
    "\"\"\"\n",
    "Prompty is a format for defining prompts with metadata.\n",
    "\n",
    "Example prompty file (customer_support.prompty):\n",
    "\n",
    "---\n",
    "name: CustomerSupport\n",
    "description: Customer support response generator\n",
    "model:\n",
    "  api: chat\n",
    "  configuration:\n",
    "    type: azure_openai\n",
    "    azure_deployment: gpt-4\n",
    "sample:\n",
    "  customer_message: \"My order is late\"\n",
    "---\n",
    "\n",
    "system:\n",
    "You are a professional customer support agent.\n",
    "Be empathetic, helpful, and provide clear solutions.\n",
    "\n",
    "user:\n",
    "Customer message: {{customer_message}}\n",
    "\n",
    "Please respond to the customer.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Prompty template example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Retrieval Augmented Generation (RAG)\n",
    "\n",
    "#### What is RAG?\n",
    "Enhance LLM responses by retrieving relevant information from a knowledge base before generating answers.\n",
    "\n",
    "#### How RAG Works:\n",
    "```\n",
    "User Query ‚Üí Search Knowledge Base ‚Üí Retrieve Relevant Docs ‚Üí \n",
    "Add to Prompt ‚Üí LLM Generates Answer\n",
    "```\n",
    "\n",
    "#### Benefits:\n",
    "- **Factual accuracy**: Ground responses in real data\n",
    "- **Up-to-date info**: Access current information\n",
    "- **Domain expertise**: Use company-specific knowledge\n",
    "- **Reduced hallucinations**: Less made-up information\n",
    "- **Transparency**: Can cite sources\n",
    "\n",
    "#### Business Use Cases:\n",
    "- Internal knowledge base Q&A\n",
    "- Product documentation search\n",
    "- Policy and compliance queries\n",
    "- Customer support with manual lookup\n",
    "- Research and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG Architecture Components:\n",
    "\n",
    "1. **Document Store**: Where knowledge is stored\n",
    "   - Azure Cognitive Search\n",
    "   - Vector databases (Pinecone, Weaviate)\n",
    "   - Azure Cosmos DB\n",
    "\n",
    "2. **Embedding Model**: Convert text to vectors\n",
    "   - OpenAI embeddings\n",
    "   - Sentence transformers\n",
    "\n",
    "3. **Retrieval System**: Find relevant documents\n",
    "   - Semantic search\n",
    "   - Keyword search\n",
    "   - Hybrid search\n",
    "\n",
    "4. **Generation Model**: Create response\n",
    "   - GPT-4, GPT-3.5\n",
    "   - Llama 2\n",
    "   - Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified RAG implementation concept\n",
    "\"\"\"\n",
    "from azure.search.documents import SearchClient\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Initialize clients\n",
    "search_client = SearchClient(endpoint, index_name, credential)\n",
    "openai_client = AzureOpenAI(api_key, endpoint)\n",
    "\n",
    "def rag_query(user_question):\n",
    "    # Step 1: Search for relevant documents\n",
    "    search_results = search_client.search(\n",
    "        search_text=user_question,\n",
    "        top=3  # Get top 3 results\n",
    "    )\n",
    "    \n",
    "    # Step 2: Extract relevant text\n",
    "    context = \"\"\n",
    "    for result in search_results:\n",
    "        context += result['content'] + \"\\n\\n\"\n",
    "    \n",
    "    # Step 3: Create prompt with context\n",
    "    prompt = f\"\"\"\n",
    "    Context information:\n",
    "    {context}\n",
    "    \n",
    "    Question: {user_question}\n",
    "    \n",
    "    Answer based on the context above:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 4: Generate response\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Answer based on provided context.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "answer = rag_query(\"What is our refund policy?\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"RAG implementation concept\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Fine-tuning Language Models\n",
    "\n",
    "#### What is Fine-tuning?\n",
    "Train a pre-trained model on your specific data to adapt it to your domain or task.\n",
    "\n",
    "#### When to Fine-tune:\n",
    "\n",
    "‚úÖ **Good candidates:**\n",
    "- Consistent task format\n",
    "- Domain-specific terminology\n",
    "- Style/tone requirements\n",
    "- Have 100+ quality examples\n",
    "- Need better performance than prompt engineering\n",
    "\n",
    "‚ùå **Not ideal:**\n",
    "- Limited training data (<50 examples)\n",
    "- Frequently changing requirements\n",
    "- Need to update knowledge regularly\n",
    "- General-purpose tasks\n",
    "\n",
    "#### Fine-tuning vs RAG vs Prompt Engineering:\n",
    "\n",
    "| Approach | Cost | Effort | Flexibility | Best For |\n",
    "|----------|------|--------|-------------|----------|\n",
    "| **Prompt Engineering** | Low | Low | High | Quick iteration |\n",
    "| **RAG** | Medium | Medium | Medium | Knowledge-based tasks |\n",
    "| **Fine-tuning** | High | High | Low | Specialized tasks |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tuning Process:\n",
    "\n",
    "1. **Prepare training data**: Format as prompt-completion pairs\n",
    "2. **Upload data**: Create dataset in Azure ML\n",
    "3. **Configure training**: Set hyperparameters\n",
    "4. **Train model**: Submit fine-tuning job\n",
    "5. **Evaluate**: Test on validation set\n",
    "6. **Deploy**: Make available for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning data format example\n",
    "\"\"\"\n",
    "Training data should be in JSONL format:\n",
    "\n",
    "{\"prompt\": \"Customer: I want to return my order. Agent:\", \"completion\": \" I'd be happy to help with your return. May I have your order number?\"}\n",
    "{\"prompt\": \"Customer: Where is my package? Agent:\", \"completion\": \" Let me check the tracking information for you. Could you provide your order number?\"}\n",
    "{\"prompt\": \"Customer: I received the wrong item. Agent:\", \"completion\": \" I apologize for the error. Let's get this corrected right away. What did you receive?\"}\n",
    "\n",
    "Best practices:\n",
    "- At least 100 examples (more is better)\n",
    "- Diverse examples covering various scenarios\n",
    "- High-quality, consistent responses\n",
    "- Clear prompt-completion separation\n",
    "- Representative of production use\n",
    "\"\"\"\n",
    "\n",
    "print(\"Fine-tuning data format guidelines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì Module 7: Practice Questions\n",
    "\n",
    "#### Question 1\n",
    "Which approach is best for quickly adapting an LLM to a new task without retraining?\n",
    "- A) Fine-tuning\n",
    "- B) Prompt engineering ‚úì\n",
    "- C) RAG\n",
    "\n",
    "**Answer: B** - Prompt engineering is the fastest way to adapt without retraining.\n",
    "\n",
    "#### Question 2\n",
    "When should you use RAG instead of fine-tuning?\n",
    "- A) When you need style/tone adaptation\n",
    "- B) When you need access to current information ‚úì\n",
    "- C) When you have limited examples\n",
    "\n",
    "**Answer: B** - RAG provides access to up-to-date information from a knowledge base.\n",
    "\n",
    "#### Question 3\n",
    "What's the minimum recommended number of examples for fine-tuning?\n",
    "- A) 10-20\n",
    "- B) 50-75\n",
    "- C) 100+ ‚úì\n",
    "\n",
    "**Answer: C** - At least 100 quality examples are recommended for effective fine-tuning.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Exam Preparation Guide\n",
    "\n",
    "### üìù DP-100 Exam Structure\n",
    "\n",
    "#### Exam Details:\n",
    "- **Duration**: 120 minutes\n",
    "- **Questions**: 40-60 questions\n",
    "- **Passing Score**: 700/1000\n",
    "- **Question Types**: Multiple choice, case studies, scenario-based\n",
    "\n",
    "#### Score Distribution:\n",
    "\n",
    "| Domain | Percentage |\n",
    "|--------|------------|\n",
    "| Design and prepare a machine learning solution | 20-25% |\n",
    "| Explore data and run experiments | 20-25% |\n",
    "| Train and deploy models | 25-30% |\n",
    "| Optimize language models for AI applications | 25-30% |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Key Topics to Master\n",
    "\n",
    "#### Domain 1: Design and Prepare\n",
    "- ‚úÖ ML problem types (classification, regression, forecasting)\n",
    "- ‚úÖ Data storage options (Blob, ADLS, SQL)\n",
    "- ‚úÖ Compute choices (CPU/GPU, instance types)\n",
    "- ‚úÖ Deployment strategies (real-time vs batch)\n",
    "- ‚úÖ MLOps architecture\n",
    "\n",
    "#### Domain 2: Explore and Experiment\n",
    "- ‚úÖ Azure ML workspace components\n",
    "- ‚úÖ Developer tools (Studio, SDK, CLI)\n",
    "- ‚úÖ AutoML configuration and tasks\n",
    "- ‚úÖ Data preparation and featurization\n",
    "- ‚úÖ Metrics selection\n",
    "\n",
    "#### Domain 3: Train and Deploy\n",
    "- ‚úÖ MLflow tracking\n",
    "- ‚úÖ Command jobs and sweep jobs\n",
    "- ‚úÖ Pipeline creation and components\n",
    "- ‚úÖ Model registration and versioning\n",
    "- ‚úÖ Endpoint deployment (online and batch)\n",
    "- ‚úÖ Blue-green deployments\n",
    "- ‚úÖ Responsible AI dashboard\n",
    "\n",
    "#### Domain 4: Optimize Language Models\n",
    "- ‚úÖ Azure AI model catalog\n",
    "- ‚úÖ Prompt engineering techniques\n",
    "- ‚úÖ RAG architecture and implementation\n",
    "- ‚úÖ Fine-tuning strategies\n",
    "- ‚úÖ Model evaluation and comparison\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìö Study Resources\n",
    "\n",
    "#### Official Microsoft Resources:\n",
    "1. **Microsoft Learn**: https://learn.microsoft.com/training/courses/dp-100t01\n",
    "2. **Exam Study Guide**: Download from Microsoft\n",
    "3. **Practice Assessments**: Take practice tests\n",
    "4. **Azure ML Documentation**: https://docs.microsoft.com/azure/machine-learning\n",
    "\n",
    "#### Hands-on Practice:\n",
    "- Complete all module labs\n",
    "- Build your own projects\n",
    "- Experiment with different services\n",
    "- Practice with sample datasets\n",
    "\n",
    "#### Community Resources:\n",
    "- Microsoft Q&A forums\n",
    "- Stack Overflow\n",
    "- LinkedIn Learning courses\n",
    "- YouTube tutorials\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Exam Tips and Strategies\n",
    "\n",
    "#### Before the Exam:\n",
    "- Review all practice questions in this manual\n",
    "- Take at least 2 practice tests\n",
    "- Set up your own Azure ML workspace and practice\n",
    "- Study case studies and scenario questions\n",
    "- Review Azure ML pricing and service limits\n",
    "\n",
    "#### During the Exam:\n",
    "- Read questions carefully (watch for \"EXCEPT\" or \"NOT\")\n",
    "- Eliminate obviously wrong answers first\n",
    "- Use process of elimination\n",
    "- Flag uncertain questions for review\n",
    "- Manage your time (2 minutes per question average)\n",
    "- For case studies, read scenario first, then questions\n",
    "\n",
    "#### Common Pitfalls:\n",
    "- Confusing online vs batch endpoints\n",
    "- Mixing up job types (command vs sweep vs pipeline)\n",
    "- Not understanding when to use AutoML vs custom training\n",
    "- Forgetting about cost optimization strategies\n",
    "- Unclear on RBAC roles and permissions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîë Key Formulas and Concepts\n",
    "\n",
    "#### Classification Metrics:\n",
    "```\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "Precision = TP / (TP + FP)\n",
    "Recall = TP / (TP + FN)\n",
    "F1 Score = 2 √ó (Precision √ó Recall) / (Precision + Recall)\n",
    "```\n",
    "\n",
    "#### Regression Metrics:\n",
    "```\n",
    "RMSE = ‚àö(Œ£(predicted - actual)¬≤ / n)\n",
    "MAE = Œ£|predicted - actual| / n\n",
    "R¬≤ = 1 - (SS_res / SS_tot)\n",
    "```\n",
    "\n",
    "#### Cross-validation:\n",
    "```\n",
    "K-fold CV: Split data into K folds\n",
    "Train on K-1 folds, validate on 1 fold\n",
    "Repeat K times, average metrics\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Quick Reference Tables\n",
    "\n",
    "#### Azure ML Job Types:\n",
    "| Job Type | Purpose | Use When |\n",
    "|----------|---------|----------|\n",
    "| Command | Single script execution | Training one model |\n",
    "| Sweep | Hyperparameter tuning | Optimizing parameters |\n",
    "| Pipeline | Multi-step workflow | Production workflows |\n",
    "\n",
    "#### RBAC Roles:\n",
    "| Role | Key Permissions |\n",
    "|------|----------------|\n",
    "| Owner | Full control |\n",
    "| Contributor | Create/modify resources |\n",
    "| AzureML Data Scientist | Run experiments, train models |\n",
    "| AzureML Compute Operator | Manage compute |\n",
    "| Reader | View only |\n",
    "\n",
    "#### Compute SKUs:\n",
    "| SKU Series | Best For |\n",
    "|------------|----------|\n",
    "| D-series | General purpose |\n",
    "| E-series | Memory optimized |\n",
    "| F-series | Compute optimized |\n",
    "| NC-series | GPU compute |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Business Analyst & Data Engineer Career Guide\n",
    "\n",
    "### Career Paths with DP-100 Certification\n",
    "\n",
    "#### Business Analyst (Data-Focused)\n",
    "**Responsibilities:**\n",
    "- Translate business problems into ML solutions\n",
    "- Define success metrics and KPIs\n",
    "- Interpret model results for stakeholders\n",
    "- Ensure model alignment with business goals\n",
    "- Monitor model performance and business impact\n",
    "\n",
    "**Key Skills from DP-100:**\n",
    "- Understanding ML problem types\n",
    "- Metrics selection and interpretation\n",
    "- AutoML for rapid prototyping\n",
    "- Model monitoring and drift detection\n",
    "- Responsible AI practices\n",
    "\n",
    "**Average Salary Range:** $75,000 - $130,000\n",
    "\n",
    "---\n",
    "\n",
    "#### Data Engineer (ML-Focused)\n",
    "**Responsibilities:**\n",
    "- Design and build data pipelines\n",
    "- Manage ML infrastructure\n",
    "- Implement MLOps workflows\n",
    "- Optimize compute and storage\n",
    "- Ensure data quality and governance\n",
    "\n",
    "**Key Skills from DP-100:**\n",
    "- Azure ML workspace management\n",
    "- Pipeline design and automation\n",
    "- Compute optimization\n",
    "- Model deployment strategies\n",
    "- Integration with Azure services\n",
    "\n",
    "**Average Salary Range:** $90,000 - $150,000\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöÄ Next Steps After Certification\n",
    "\n",
    "#### Immediate Actions:\n",
    "1. Update LinkedIn profile with certification\n",
    "2. Add certification badge to resume\n",
    "3. Share achievement on professional networks\n",
    "4. Start building portfolio projects\n",
    "\n",
    "#### Portfolio Project Ideas:\n",
    "1. **Customer Segmentation**: Cluster analysis on customer data\n",
    "2. **Churn Prediction**: Classification model with monitoring\n",
    "3. **Sales Forecasting**: Time-series forecasting pipeline\n",
    "4. **Sentiment Analysis**: NLP with fine-tuned models\n",
    "5. **Recommendation System**: Collaborative filtering with deployment\n",
    "\n",
    "#### Continuing Education:\n",
    "- **Related Certifications**:\n",
    "  - DP-203: Azure Data Engineer Associate\n",
    "  - AI-102: Azure AI Engineer Associate\n",
    "  - PL-300: Power BI Data Analyst Associate\n",
    "  \n",
    "- **Advanced Topics**:\n",
    "  - Deep learning with PyTorch/TensorFlow\n",
    "  - Advanced MLOps with Azure DevOps\n",
    "  - Real-time ML with Azure Stream Analytics\n",
    "  - Cost optimization strategies\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìå Final Checklist\n",
    "\n",
    "Before considering yourself exam-ready, ensure you can:\n",
    "\n",
    "#### Design (20-25%):\n",
    "- [ ] Identify appropriate ML task types\n",
    "- [ ] Design data ingestion solutions\n",
    "- [ ] Choose appropriate Azure services\n",
    "- [ ] Plan deployment strategies\n",
    "- [ ] Design monitoring solutions\n",
    "\n",
    "#### Explore (20-25%):\n",
    "- [ ] Create and configure workspaces\n",
    "- [ ] Use Studio, SDK, and CLI\n",
    "- [ ] Configure AutoML experiments\n",
    "- [ ] Prepare and featurize data\n",
    "- [ ] Select and interpret metrics\n",
    "\n",
    "#### Train and Deploy (25-30%):\n",
    "- [ ] Track experiments with MLflow\n",
    "- [ ] Submit command and sweep jobs\n",
    "- [ ] Create and run pipelines\n",
    "- [ ] Register and version models\n",
    "- [ ] Deploy to endpoints\n",
    "- [ ] Implement blue-green deployments\n",
    "\n",
    "#### Optimize (25-30%):\n",
    "- [ ] Browse and deploy catalog models\n",
    "- [ ] Apply prompt engineering\n",
    "- [ ] Implement RAG solutions\n",
    "- [ ] Fine-tune language models\n",
    "- [ ] Evaluate model performance\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've completed the DP-100 Student Manual. You now have the knowledge and skills to:\n",
    "- Design end-to-end ML solutions on Azure\n",
    "- Build and deploy production ML models\n",
    "- Implement MLOps best practices\n",
    "- Work effectively as a Business Analyst or Data Engineer\n",
    "\n",
    "**Good luck on your DP-100 exam and your ML career journey!**\n",
    "\n",
    "---\n",
    "\n",
    "### üìû Additional Resources\n",
    "\n",
    "**Microsoft Learn**: learn.microsoft.com/training/paths/azure-machine-learning\n",
    "\n",
    "**Azure ML Documentation**: docs.microsoft.com/azure/machine-learning\n",
    "\n",
    "**Exam Registration**: learn.microsoft.com/certifications/exams/dp-100\n",
    "\n",
    "**Community Forums**: techcommunity.microsoft.com/t5/azure-ai-services/ct-p/Azure-AI\n",
    "\n",
    "---\n",
    "\n",
    "*Version: 1.0 | Last Updated: February 2026*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
